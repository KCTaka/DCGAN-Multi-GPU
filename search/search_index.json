{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DCGAN training for Multi-GPU from scrach using PyTorch","text":"<p>This project implements a model based on the paper Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks and the original GAN paper by Ian Goodfellow et al. The code includes <code>torchrun</code> capabilities for distributed training on multi-GPU. Mutiple machines not supported.  The aim of this project is to familiarize myself with the distributive training process that often goes hidden when learning about machine learning. Furthermore, this would develop my skill in torchrun and pytorch allowing a more fundamental understanding behind the pytorch framework. </p>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>You can install required libraroes.</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"#running-the-code","title":"Running the Code","text":"<p>To run the code, use the following command:</p> <pre><code>torchrun --standalone --nproc_per_node=gpu torchrun_main.py\n</code></pre>"},{"location":"#result","title":"Result","text":"<p>After 300 epochs</p> <p> </p> <p>The above are generated image from noise. It does not look satisfactory, I will attempt to implement a perceptual loss as well such that I can track best outcome while minimizing perceptual discrepency. </p> <p></p> <p>Generally the discriminator learns fairly quickly, not allowing the generator to catch up resulting in the above graph. Either increasing m or descreasing k should provide a more stable outcome. Lower batch-size with lower learninig rate could also work. Finding the right hyperparameters should be done through Optuna or W&amp;B Sweeps. </p>"},{"location":"#hyperparameters","title":"Hyperparameters","text":"<p>All hyperparameters and values must be edited directly in the code. Future updates will include a more flexible configuration system.</p>"},{"location":"#references","title":"References","text":"<ul> <li>Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</li> <li>Generative Adversarial Networks by Ian Goodfellow et al.</li> </ul>"},{"location":"reflection/","title":"DCGAN Reflection","text":""},{"location":"reflection/#motivation","title":"Motivation","text":"<p>When I just heard about CNNs and image generation, I wondered how a neural network capable of generating such fine details is trained; it was a enigma for me as on how to tell the neural network which direction to update itself to improve its generation. The concept of GAN, being a tug-of-war-like training method, intrigued and enticed me to further explore how far I can bring this concept to life. I was initially introduced to the potential of the model in https://thispersondoesnotexist.com/, and properly in depth during an APS360 course at the University of Toronto. I decided to read the official original GAN paper and decided to implement it myself with a slight twist</p>"},{"location":"reflection/#problems","title":"Problems","text":"<p>I've faced many problems during this project as I was writing raw pytorch and torchrun code following the official documents and tutorials (https://www.youtube.com/watch?v=-LAtx9Q6DA8). </p> <ul> <li>The loss calculation for when training the generator is slightly different in the paper than what I'd see in other implementations</li> </ul> <p>The paper says to maximize the BCELoss with 0, whereas the other implementation (including this project) minimized the BCELoss with 1. Both effectively do similar things but mathematically should be quite different. I'm not too sure as to why there is this difference, but I presume both method works</p> <ul> <li>Tough to figure whether the training was working. </li> </ul> <p>I would often test the program out many times and it would resort to unsatisfactory results and black images, and would leave me confused on whether the hyperparameter is bad, algorithm is implemented poorly/inaccurately, or there is a coding mistake. This would often lead to time consuming debugging process as it is not fast to see it in working progress.</p>"},{"location":"reflection/#outline","title":"Outline","text":"<p>The paper originally describes to update the discriminator k times before updating the generator once. I implemented to update the discriminator k times before updating the generator m times. This allowed precise ratio between the discriminator and generator parameter updates. However, I assume the reason why the author did not do this is due to several other factors that can help balance the learning strength of discrminator and generator. </p> <p>Algorithm 1: Minibatch Stochastic Gradient Descent Training of GANs</p> <pre><code>for number of training iterations do\n    for k steps do\n        sample minibatch of m noise samples {z^(1), \u2026, z^(m)} from noise prior p_g(z)\n        sample minibatch of m examples {x^(1), \u2026, x^(m)} from data generating distribution p_data(x)\n        update the discriminator by ascending its stochastic gradient:\n            \u2207_\u03b8d (1/m) \u03a3_{i=1}^m [ log D(x^(i)) + log(1 \u2212 D(G(z^(i)))) ]\n    end for\n    sample minibatch of m noise samples {z^(1), \u2026, z^(m)} from noise prior p_g(z)\n    update the generator by descending its stochastic gradient:\n        \u2207_\u03b8g (1/m) \u03a3_{i=1}^m [ log(1 \u2212 D(G(z^(i)))) ]\n</code></pre>"}]}